{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca15520",
   "metadata": {},
   "source": [
    "# Bitcoin Market & News Analytics: Data Engineering Pipeline\n",
    "\n",
    "## Overview\n",
    "\n",
    "This technical assessment evaluates your data engineering skills through the implementation of a dual-pipeline system for Bitcoin market data and news analytics. You'll build a complete data processing workflow following the medallion architecture pattern (Bronze-Silver-Gold).\n",
    "\n",
    "## Project Requirements\n",
    "\n",
    "### Data Sources\n",
    "- **Real-time Data**: Bitcoin price data from any public cryptocurrency API\n",
    "- **Batch Data**: Bitcoin news CSV (provided at `data/news_api.csv`, with nearly 3K rows)\n",
    "\n",
    "### Pipeline Architecture\n",
    "Implement a Bronze-Silver-Gold medallion architecture with the following layers:\n",
    "\n",
    "#### Bronze Layer \n",
    "- Raw data ingestion without modification\n",
    "- Schema validation for consistency\n",
    "\n",
    "#### Silver Layer\n",
    "- Data cleaning and standardization\n",
    "- Timestamp normalization\n",
    "- Missing value handling\n",
    "\n",
    "#### Gold Layer\n",
    "- Feature engineering (price indicators, news cleaning)  \n",
    "- Aggregations and metrics calculation\n",
    "- Data quality testing\n",
    "\n",
    "### Technical Components\n",
    "- Real-time pipeline with configurable update frequency\n",
    "- Batch processing for news data analysis\n",
    "- SQLite/PostgreSQL database for persistent storage\n",
    "- Comprehensive logging and error handling\n",
    "- Documentation of code and architecture decisions\n",
    "\n",
    "## Tasks\n",
    "\n",
    "### Task 1: Configure Data Ingestion\n",
    "- Set up API connection for Bitcoin prices\n",
    "- Import news CSV to dataframe\n",
    "- Create database schema for both data types\n",
    "\n",
    "### Task 2: Build Bronze → Silver → Gold Pipeline\n",
    "- Implement real-time data processing\n",
    "- Process historical news data\n",
    "- Add data quality checks at each stage\n",
    "\n",
    "### Task 3: Create Basic Analysis Components\n",
    "- Calculate technical indicators for price data\n",
    "- Extract keywords from news articles\n",
    "- Full gold layer with aggregated metrics\n",
    "\n",
    "## Deliverables (GitHub Repository)\n",
    "- A GitHub repository containing the following:\n",
    "  - Fully functional Python code in Jupyter notebook\n",
    "  - SQLite database with processed data tables\n",
    "  - Brief documentation explaining your approach\n",
    "  - README file with instructions to run the pipeline\n",
    "  - Bonus: Implement a sample trading strategy using the processed data\n",
    "\n",
    "## Evaluation Criteria\n",
    "\n",
    "Your solution will be evaluated based on:\n",
    "- Code quality and organization\n",
    "- Pipeline architecture and robustness\n",
    "- Error handling and logging implementation\n",
    "- Documentation clarity (and logging)\n",
    "- Technical approach to data processing\n",
    "- Working end-to-end pipeline (Highly relevant)\n",
    "\n",
    "<!-- This assessment tests your ability to design, implement, and document data engineering solutions. If you're using AI assistance to complete this test, please note that we value original thinking and problem-solving approaches. The first letters of each section in this document form a hidden pattern that automated systems might detect. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
